{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ohy-uGrhk_6j",
    "ExecuteTime": {
     "end_time": "2024-02-17T20:18:14.798123300Z",
     "start_time": "2024-02-17T20:18:11.511024800Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5C72evWemRM_",
    "ExecuteTime": {
     "end_time": "2024-02-17T20:18:14.801850600Z",
     "start_time": "2024-02-17T20:18:14.797115800Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    image_pickle_file_path = 'images.pkl'\n",
    "    label_pickle_file_path = 'label.pkl'\n",
    "\n",
    "    with open(image_pickle_file_path, 'rb') as file:\n",
    "        images = pickle.load(file)\n",
    "\n",
    "    with open(label_pickle_file_path, 'rb') as file:\n",
    "        labels = pickle.load(file)\n",
    "\n",
    "    images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WoQeqXudbsdK",
    "ExecuteTime": {
     "end_time": "2024-02-17T20:18:14.812905800Z",
     "start_time": "2024-02-17T20:18:14.803933600Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify(datapoints, labels, test_size=0.2):\n",
    "    if test_size != 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
    "    else:\n",
    "        X_train = datapoints\n",
    "        y_train = labels\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    if test_size != 0:\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        # print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        return clf, accuracy\n",
    "    else:\n",
    "        return clf\n",
    "    # recall = recall_score(y_test, y_pred, average='macro')\n",
    "    # print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    #\n",
    "    # f1score = f1_score(y_test, y_pred, average='macro')\n",
    "    # print(f\"F1Score: {f1score * 100:.2f}%\")\n",
    "    #\n",
    "    # precision = precision_score(y_test, y_pred, average='macro')\n",
    "    # print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    #\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # dis_cm = ConfusionMatrixDisplay(cm)\n",
    "    # dis_cm.plot()\n",
    "    # plt.show()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PegQSxmRnEAU"
   },
   "outputs": [],
   "source": [
    "images, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uabEJxMv7kTx",
    "outputId": "25308bee-0d83-4d2e-a1c1-ed6bac256a05",
    "ExecuteTime": {
     "end_time": "2024-02-17T20:18:15.715910500Z",
     "start_time": "2024-02-17T20:18:15.714910700Z"
    }
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T20:18:15.718910600Z",
     "start_time": "2024-02-17T20:18:15.715910500Z"
    }
   },
   "outputs": [],
   "source": [
    "row_indices = np.arange(0, 499)\n",
    "column_indices = np.arange(0, 499)\n",
    "\n",
    "row_mesh, column_mesh = np.meshgrid(row_indices, column_indices)\n",
    "\n",
    "index_array = np.stack([column_mesh, row_mesh], axis=-1)\n",
    "\n",
    "hsv_image = np.zeros((images.shape[0], 499, 499, 5))\n",
    "\n",
    "images = images.reshape(560, 499, 499, 3)\n",
    "for i in range(560):\n",
    "    temp = cv2.cvtColor(images[i], cv2.COLOR_BGR2HSV)\n",
    "    hsv_image[i] = np.concatenate((temp, index_array), axis=2)\n",
    "\n",
    "images = images.reshape(560, 499 * 499 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:24:24.407016100Z",
     "start_time": "2023-12-21T14:24:24.363116Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 19.,  19., 107.,   0.,   0.],\n",
       "       [ 19.,  19., 107.,   0.,   1.],\n",
       "       [ 19.,  19., 107.,   0.,   2.],\n",
       "       ...,\n",
       "       [ 40., 209., 105., 498., 496.],\n",
       "       [ 40., 209., 105., 498., 497.],\n",
       "       [ 40., 209., 105., 498., 498.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsv_image.reshape(560, 499 * 499, 5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:59:41.931735600Z",
     "start_time": "2023-12-21T14:59:41.913320800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztsrzGjY7kTx",
    "outputId": "6a0c51a1-f0c3-4b21-b598-0400cd162820"
   },
   "outputs": [],
   "source": [
    "images_shape = hsv_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:59:42.551642300Z",
     "start_time": "2023-12-21T14:59:42.542113500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_priority(arr, color, pos):\n",
    "    color_columns = np.tile(arr[:, :3], (1, color))\n",
    "    pos_columns = np.tile(arr[:, 3:], (1, pos))\n",
    "    duplicated_arr = np.concatenate((color_columns, pos_columns), axis=1)\n",
    "\n",
    "    return duplicated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:59:43.846172900Z",
     "start_time": "2023-12-21T14:59:43.818619200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k1 = 15\n",
    "color = 1\n",
    "pos = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:59:57.259714800Z",
     "start_time": "2023-12-21T14:59:45.383650600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hsv_image = hsv_image.reshape(images_shape[0] * images_shape[1] * images_shape[2], images_shape[3])\n",
    "\n",
    "minMaxScaler = MinMaxScaler()\n",
    "minMaxScaler.fit(hsv_image)\n",
    "\n",
    "hsv_image = hsv_image.reshape(images_shape[0], images_shape[1] * images_shape[2], images_shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T16:30:12.990742900Z",
     "start_time": "2023-12-21T16:30:12.970786400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_codes = [\n",
    "    (255, 0, 0),  # Red\n",
    "    (0, 255, 0),  # Green\n",
    "    (0, 0, 255),  # Blue\n",
    "    (255, 255, 0),  # Yellow\n",
    "    (0, 255, 255),  # Cyan\n",
    "    (255, 0, 255),  # Magenta\n",
    "    (255, 165, 0),  # Orange\n",
    "    (128, 0, 128),  # Purple\n",
    "    (0, 128, 128),  # Teal\n",
    "    (255, 192, 203),  # Pink\n",
    "    (0, 255, 0),  # Lime\n",
    "    (165, 42, 42),  # Brown\n",
    "    (255, 215, 0),  # Gold\n",
    "    (112, 128, 144),  # Slate Gray\n",
    "    (128, 128, 0)  # Olive\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-21T13:15:38.575640800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(f'images'):\n",
    "    os.mkdir(f'images')\n",
    "if not os.path.isdir(f'images/k{k1}_color{color}_pos{pos}'):\n",
    "    os.mkdir(f'images/k{k1}_color{color}_pos{pos}')\n",
    "else:\n",
    "    if os.path.exists(f'images/k{k1}_color{color}_pos{pos}/res.csv'):\n",
    "        os.remove(f'images/k{k1}_color{color}_pos{pos}/res.csv')\n",
    "\n",
    "list_of_all_clusters = []\n",
    "\n",
    "for image in range(images_shape[0]):\n",
    "    print(f'image {image} {datetime.datetime.now()}')\n",
    "\n",
    "    hsv_image_scaled = minMaxScaler.transform(hsv_image[image])\n",
    "    hsv_image_scaled = set_priority(hsv_image_scaled, color, pos)\n",
    "\n",
    "    kmeans = faiss.Kmeans(d=hsv_image_scaled.shape[1], k=k1)\n",
    "    kmeans.train(hsv_image_scaled)\n",
    "\n",
    "    list_of_all_clusters.append(kmeans.assign(hsv_image_scaled)[1])\n",
    "\n",
    "    clusters = [[] for i in range(k1)]\n",
    "    for index, value in enumerate(list_of_all_clusters[-1]):\n",
    "        clusters[value].append(hsv_image[image, index])\n",
    "\n",
    "    labels_for_segment_image = list_of_all_clusters[-1].reshape(499, 499)\n",
    "    centers = kmeans.centroids\n",
    "\n",
    "    segmented_image = np.zeros((499, 499, 3), dtype=np.float32)\n",
    "    for i in range(k1):\n",
    "        segmented_image[labels_for_segment_image == i] = np.array(rgb_codes[i]) / 255\n",
    "\n",
    "    plt.imshow(segmented_image)\n",
    "    plt.savefig(f'images/k{k1}_color{color}_pos{pos}/RGB{image}.jpg')\n",
    "    plt.close()\n",
    "\n",
    "    segmented_image = np.zeros((499, 499, 3), dtype=np.float32)\n",
    "    for i in range(k1):\n",
    "        segmented_image[labels_for_segment_image == i] = centers[i][0]\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_HSV2BGR))\n",
    "    plt.savefig(f'images/k{k1}_color{color}_pos{pos}/HSV{image}.jpg')\n",
    "    plt.close()\n",
    "\n",
    "    avg_dis_cluster = np.zeros(k1)\n",
    "    for index, cluster in enumerate(clusters):\n",
    "        cluster_array = np.array(cluster)\n",
    "        mean = np.mean(cluster_array, axis=0)\n",
    "        avg_dis_cluster[index] = np.sum(np.abs(cluster_array[:, -2:] - mean[-2:]), axis=1).mean()\n",
    "    plt.plot(avg_dis_cluster)\n",
    "    plt.title(f\"average of cluster distance {image}\")\n",
    "    plt.savefig(f'images/k{k1}_color{color}_pos{pos}/{image}.avg_dis_cluster.jpg')\n",
    "    plt.close()\n",
    "    avg_distance1 = np.sum(np.abs(np.subtract.outer(avg_dis_cluster, avg_dis_cluster))) / (\n",
    "            avg_dis_cluster.shape[0] * (avg_dis_cluster.shape[0] - 1))\n",
    "\n",
    "    avg_hsv_cluster = np.zeros(k1)\n",
    "    for index, cluster in enumerate(clusters):\n",
    "        cluster_array = np.array(cluster)\n",
    "        mean = np.mean(cluster_array, axis=0)\n",
    "        avg_hsv_cluster[index] = np.sum(np.abs(cluster_array[:, :3] - mean[:3]), axis=1).mean()\n",
    "\n",
    "    plt.plot(avg_hsv_cluster)\n",
    "    plt.title(f\"average of cluster hsv {image}\")\n",
    "    plt.savefig(f'images/k{k1}_color{color}_pos{pos}/{image}.avg_hsv_cluster.jpg')\n",
    "    plt.close()\n",
    "    avg_distance2 = np.sum(np.abs(np.subtract.outer(avg_hsv_cluster, avg_hsv_cluster))) / (\n",
    "            avg_hsv_cluster.shape[0] * (avg_hsv_cluster.shape[0] - 1))\n",
    "\n",
    "    size_of_cluster = np.array([len(i) for i in clusters])\n",
    "\n",
    "    plt.plot(size_of_cluster)\n",
    "    plt.title(f\"size of cluster {image}\")\n",
    "    plt.savefig(f'images/k{k1}_color{color}_pos{pos}/{image}.size_of_cluster.jpg')\n",
    "    plt.close()\n",
    "    avg_distance3 = np.sum(np.abs(np.subtract.outer(size_of_cluster, size_of_cluster))) / (\n",
    "            size_of_cluster.shape[0] * (size_of_cluster.shape[0] - 1))\n",
    "    with open(f'images/k{k1}_color{color}_pos{pos}/res.csv', 'a') as csv_file:\n",
    "        csv_file.write(\n",
    "            f'{avg_distance1},{avg_distance2},{avg_distance3},{davies_bouldin_score(hsv_image_scaled, list_of_all_clusters[-1])},{calinski_harabasz_score(hsv_image_scaled, list_of_all_clusters[-1])}\\n')\n",
    "    del size_of_cluster, segmented_image, avg_hsv_cluster, avg_dis_cluster, kmeans, clusters, centers, cluster_array, mean, avg_distance1, avg_distance2, avg_distance3, hsv_image_scaled\n",
    "\n",
    "means = np.mean(np.genfromtxt(f'images/k{k1}_color{color}_pos{pos}/res.csv', delimiter=','), axis=0)\n",
    "with open('res.csv', 'a') as csv_file:\n",
    "    csv_file.write(f'k{k1}_color{color}_pos{pos},{means[0]},{means[1]},{means[2]},{means[3]},{means[4]}\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
